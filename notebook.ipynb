{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0a303b4",
   "metadata": {},
   "source": [
    "# Classifying Planets\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this classification problem, we embark on a journey where we are presented with a synthetic dataset of planets and moons of our solar system. Our mission is clear: **classify from an image the planet or moon**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34e8565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 11:50:02.780920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2264526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "seed = 77\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38958551",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024eff93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory data/raw",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mdata/raw\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     labels\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minferred\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     label_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     color_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrgb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     image_size\u001b[39m=\u001b[39;49m(\u001b[39m128\u001b[39;49m, \u001b[39m128\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/dev/heig-vd/a-guide-to-mlops/.venv/lib/python3.11/site-packages/keras/utils/image_dataset.py:210\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     seed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m1e6\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m image_paths, labels, class_names \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39;49mindex_directory(\n\u001b[1;32m    211\u001b[0m     directory,\n\u001b[1;32m    212\u001b[0m     labels,\n\u001b[1;32m    213\u001b[0m     formats\u001b[39m=\u001b[39;49mALLOWLIST_FORMATS,\n\u001b[1;32m    214\u001b[0m     class_names\u001b[39m=\u001b[39;49mclass_names,\n\u001b[1;32m    215\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    216\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    217\u001b[0m     follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m label_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(class_names) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    222\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mWhen passing `label_mode=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`, there must be exactly 2 \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    223\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclass_names. Received: class_names=\u001b[39m\u001b[39m{\u001b[39;00mclass_names\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/heig-vd/a-guide-to-mlops/.venv/lib/python3.11/site-packages/keras/utils/dataset_utils.py:542\u001b[0m, in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m     subdirs \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(tf\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mgfile\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[1;32m    543\u001b[0m         \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    544\u001b[0m             \u001b[39mif\u001b[39;00m subdir\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/dev/heig-vd/a-guide-to-mlops/.venv/lib/python3.11/site-packages/tensorflow/python/lib/io/file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \n\u001b[1;32m    755\u001b[0m \u001b[39mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_directory(path):\n\u001b[0;32m--> 768\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError(\n\u001b[1;32m    769\u001b[0m       node_def\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    770\u001b[0m       op\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    771\u001b[0m       message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not find directory \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(path))\n\u001b[1;32m    773\u001b[0m \u001b[39m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[39m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    776\u001b[0m     compat\u001b[39m.\u001b[39mas_str_any(filename)\n\u001b[1;32m    777\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m _pywrap_file_io\u001b[39m.\u001b[39mGetChildren(compat\u001b[39m.\u001b[39mpath_to_bytes(path))\n\u001b[1;32m    778\u001b[0m ]\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory data/raw"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"data/raw\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdb3d8dc",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data shape:', dataset.element_spec[0].shape)\n",
    "print('Data type:', dataset.element_spec[0].dtype)\n",
    "print('Label shape:', dataset.element_spec[1].shape)\n",
    "print('Label type:', dataset.element_spec[1].dtype)\n",
    "\n",
    "labels = dataset.class_names\n",
    "\n",
    "# Print the labels\n",
    "print(\"Labels:\")\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"{i:4}: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 10 sample images\n",
    "plt.figure(figsize=(10, 5), tight_layout=True)\n",
    "for images, label_idxs in dataset.take(1):\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(labels[label_idxs[i].numpy()])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdfa8f4a",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "The following steps are performed to prepare the data:\n",
    "\n",
    "- Shuffling the data\n",
    "- Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"data/raw\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(32, 32),\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 10 sample images\n",
    "plt.figure(figsize=(10, 5), tight_layout=True)\n",
    "for images, label_idxs in ds_train.take(1):\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"), cmap=\"gray\")\n",
    "        plt.title(labels[label_idxs[i].numpy()])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7cc0268",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(32, 32, 1)\n",
    "        ),\n",
    "        tf.keras.layers.MaxPooling2D((3, 3)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(11),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fefaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=5,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c27ea210",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "history = model.history.history\n",
    "epochs = range(1, len(history[\"loss\"]) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(epochs, history[\"loss\"], label=\"Training loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.xticks(epochs)\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a22751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print validation metrics\n",
    "val_loss, val_acc = model.evaluate(ds_test)\n",
    "print(f\"Validation loss: {val_loss:.2f}\")\n",
    "print(f\"Validation accuracy: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 10 random images from the test set and show the model's predictions\n",
    "plt.figure(figsize=(10, 5), tight_layout=True)\n",
    "for images, label_idxs in ds_test.take(1):\n",
    "    preds = model.predict(images)\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        img = images[i].numpy().astype(\"uint8\")\n",
    "        # Convert image to rgb if grayscale\n",
    "        if img.shape[-1] == 1:\n",
    "            img = np.squeeze(img, axis=-1)\n",
    "            img = np.stack((img,) * 3, axis=-1)\n",
    "        true_label = labels[label_idxs[i].numpy()]\n",
    "        pred_label = labels[np.argmax(preds[i])]\n",
    "        # Add red border if the prediction is wrong else add green border\n",
    "        img = np.pad(img, pad_width=((1, 1), (1, 1), (0, 0)))\n",
    "        if true_label != pred_label:\n",
    "            img[0,:,0] = 255  # Top border\n",
    "            img[-1,:,0] = 255  # Bottom border\n",
    "            img[:,0,0] = 255  # Left border\n",
    "            img[:,-1,0] = 255  # Right border\n",
    "        else:\n",
    "            img[0,:,1] = 255\n",
    "            img[-1,:,1] = 255\n",
    "            img[:,0,1] = 255\n",
    "            img[:,-1,1] = 255\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.title(\n",
    "            f\"True: {true_label}\\n\"\n",
    "            f\"Pred: {pred_label}\"\n",
    "        )\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c98071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix of confidence per class for the test set\n",
    "plt.figure(figsize=(6, 6), tight_layout=True)\n",
    "preds = model.predict(ds_test)\n",
    "\n",
    "conf_matrix = tf.math.confusion_matrix(\n",
    "    labels=tf.concat([y for _, y in ds_test], axis=0),\n",
    "    predictions=tf.argmax(preds, axis=1),\n",
    "    num_classes=len(labels),\n",
    ")\n",
    "\n",
    "conf_matrix = conf_matrix / tf.reduce_sum(conf_matrix, axis=1)\n",
    "plt.imshow(conf_matrix)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the model's predictions using Grad-CAM\n",
    "def make_gradcam_heatmap(img, grad_model):\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 32, 32, 1)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Resize and convert the image\n",
    "    input_w = grad_model.input_shape[1]\n",
    "    input_h = grad_model.input_shape[2]\n",
    "    img = tf.image.resize(img, (input_w, input_h))\n",
    "    grayscale = grad_model.input_shape[3] == 1\n",
    "    if grayscale:\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "\n",
    "    # We compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img)\n",
    "        pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# We create a model that maps the input image to the activations\n",
    "# of the last conv layer as well as the output predictions\n",
    "last_conv_layer = list(filter(lambda x: \"conv\" in x.name, model.layers))[-1]\n",
    "grad_model = tf.keras.models.Model(\n",
    "    model.inputs, [last_conv_layer.output, model.output]\n",
    ")\n",
    "\n",
    "data_path = Path(\"data/raw\")\n",
    "classes = sorted(filter(lambda p: p.is_dir(), data_path.glob(\"*\")))\n",
    "\n",
    "plt.figure(figsize=(11, 16), tight_layout=True)\n",
    "for i, class_path in enumerate(classes):\n",
    "    img_path = list(sorted(class_path.glob(\"*\")))[0]\n",
    "    img_fn = img_path.name\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    heatmap = make_gradcam_heatmap(img, grad_model)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = plt.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    plt.subplot(6, 4, i * 2 + 1)\n",
    "    plt.imshow(img / 255)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(img_fn)\n",
    "\n",
    "    plt.subplot(6, 4, i * 2 + 2)\n",
    "    plt.imshow(jet_heatmap / 255)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(img_fn + \" (Grad-CAM)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
