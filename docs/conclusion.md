# Conclusion

Congratulations! You did it! You were able to convert a ML experiment with a traditional approach to a well-defined,
well-documented workflow that can scale and serve a model to the outside world! Let's take the time to make a summary
of what you have done.

## Summary of what you have done

- ✅ The codebase can be shared among the developers

Thanks to Git, the codebase can be shared and improved collectively among the developers.

- ✅ The dataset can be shared among the developers

Thanks to DVC, the dataset can be shared and improved collectively among the developers.

- ✅ The model can be reproduced

Thanks to DVC, the steps to create the model are documented and can be executed in order to reproduce the model.

- ✅ The experiment can be executed on a clean machine

Thanks to the CI/CD pipeline, the experiment can be executed on a clean machine. Erasing the "but it works on my machine" issue.

- ✅  The changes done to a model can be tracked

Thanks to DVC and CML, the changes done to a model can be tracked, discussed and visualized before merging them.

- ✅ The model can be used outside of the experiment context

Thanks to MLEM, the model can be served and be used outside of the experiment context.

- ✅ The model can be deployed and accessed on Kubernetes

Thanks to MLEM, the model can be deployed and be accessed on a Kubernetes server.

- ✅ The model can be trained on a Kubernetes pod

Thanks to CML, the model can be trained on specialized hardware on a Kubernetes pod.

## End of your journey

We appreciate your continued support! We trust that you found this guide enjoyable and informative. We have additional content available on advanced concepts and labelization topics, which we believe might pique your interest. Feel free to explore the left sidebar for more MLOps-related resources.

If you encounter any difficulties, please don't hesitate to reach out to us on [GitHub](https://github.com/csia-pme/a-guide-to-mlops). Happy learning! :)
